{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fcc718-84d6-4509-a0d6-c45039b1be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import jax.numpy as jnp\n",
    "from sr_rom.data.data import process_data, split_data\n",
    "from alpine.data import Dataset\n",
    "from alpine.gp import gpsymbreg as gps\n",
    "from typing import Callable, Tuple, List\n",
    "import ray\n",
    "from deap import gp\n",
    "from deap.base import Toolbox\n",
    "import time\n",
    "import sys\n",
    "import yaml\n",
    "from dctkit import config\n",
    "from jax import jit, grad\n",
    "import pygmo as pg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor,nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd86003-6966-445d-963e-f50a5720bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_array, A_B_list = process_data(5, \"2dcyl/Re200_300_rank5\")\n",
    "train_data, val_data, test_data = split_data(k_array, A_B_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d08d39-ff90-44a8-aeaa-56b905e0740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "train_A_i_j = [A_B['A'][i, j]for A_B in train_data.y]\n",
    "val_A_i_j = [A_B['A'][i, j]for A_B in val_data.y]\n",
    "test_A_i_j = [A_B['A'][i, j]for A_B in test_data.y]\n",
    "train_val_A_i_j = train_A_i_j + val_A_i_j\n",
    "train_data_i_j = Dataset(\"k_component\", jnp.array(\n",
    "    train_data.X), jnp.array(train_A_i_j))\n",
    "val_data_i_j = Dataset(\"k_component\", jnp.array(val_data.X), jnp.array(val_A_i_j))\n",
    "test_data_i_j = Dataset(\"k_component\", jnp.array(\n",
    "    test_data.X), jnp.array(test_A_i_j))\n",
    "train_val_data_i_j = Dataset(\n",
    "    \"k_component\", jnp.array(train_data.X + val_data.X), jnp.array(train_val_A_i_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8fcb789f-dff3-4eb8-ac9c-33e55821a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2000,  0.8023],\n",
      "        [ 0.2050,  0.0202],\n",
      "        [ 0.2100, -0.5586],\n",
      "        [ 0.2150,  0.0577],\n",
      "        [ 0.2200,  0.1239],\n",
      "        [ 0.2250, -0.6777],\n",
      "        [ 0.2300,  0.6804],\n",
      "        [ 0.2350, -0.1142],\n",
      "        [ 0.2400, -0.6205],\n",
      "        [ 0.2450, -0.2366],\n",
      "        [ 0.2500, -0.9647],\n",
      "        [ 0.2550,  1.1141],\n",
      "        [ 0.2600, -0.9201],\n",
      "        [ 0.2650,  0.8682],\n",
      "        [ 0.2700, -0.9703],\n",
      "        [ 0.2750, -1.0082],\n",
      "        [ 0.2800, -0.8678],\n",
      "        [ 0.2850, -0.4624]])\n",
      "tensor([[ 0.2900, -0.2588],\n",
      "        [ 0.2950, -0.4107],\n",
      "        [ 0.3000,  1.1167]])\n"
     ]
    }
   ],
   "source": [
    "# init tensor\n",
    "training_data = torch.zeros((len(train_val_data_i_j.X),2))\n",
    "test_data = torch.zeros((len(test_data_i_j.X),2))\n",
    "\n",
    "\n",
    "training_data[:,0] = tensor(np.array(train_val_data_i_j.X))/1000\n",
    "training_data[:,1] = tensor(np.array(train_val_data_i_j.y))\n",
    "#training_data[:,1] = tensor(np.array(np.sqrt(train_val_data_i_j.X)))\n",
    "\n",
    "\n",
    "test_data[:,0] = tensor(np.array(test_data_i_j.X))/1000\n",
    "test_data[:,1] = tensor(np.array(test_data_i_j.y))\n",
    "#test_data[:,1] = tensor(np.array(np.sqrt(test_data_i_j.X)))\n",
    "\n",
    "print(training_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ed87e0c-9ab8-422a-a94c-d4b56f0bbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=18, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4d5bb362-90b5-4af6-9482-622298d2d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1, 40),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(40, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 40),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0c1f85a4-0ffc-4e04-b803-2a816aa9840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    X = dataloader.dataset[:,0].reshape(-1,1)\n",
    "    y = dataloader.dataset[:,1].reshape(-1,1)\n",
    "    #print(X)\n",
    "    #print(\"-------\")\n",
    "    #print(y)\n",
    "    #print(\"AAAAAAAAAAAAAA\")\n",
    "    # Compute prediction and loss\n",
    "    pred = model(X)\n",
    "    #train_loss = torch.sum((pred-y)**2)/size\n",
    "    train_loss = loss_fn(pred, y)\n",
    "    #print(y)\n",
    "\n",
    "    # Backpropagation\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_loss = train_loss.item()\n",
    "    #print(size)\n",
    "\n",
    "    print(f\"Train Avg loss: {train_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9972da79-582c-42ae-893a-2acc554df372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    X = dataloader.dataset[:,0].reshape(-1,1)\n",
    "    y = dataloader.dataset[:,1].reshape(-1,1)\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients \n",
    "    # are computed during test mode and also serves to reduce unnecessary \n",
    "    # gradient computations and memory usage for tensors with requires_grad = True\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        test_loss =loss_fn(pred, y)\n",
    "\n",
    "    print(f\"Test Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e33df146-673a-4414-a98b-52013e3b6fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Avg loss: 0.529088\n",
      "Test Avg loss: 0.484589 \n",
      "\n",
      "Epoch 10001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.519350\n",
      "Test Avg loss: 0.488836 \n",
      "\n",
      "Epoch 20001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.511077\n",
      "Test Avg loss: 0.493278 \n",
      "\n",
      "Epoch 30001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.504024\n",
      "Test Avg loss: 0.497824 \n",
      "\n",
      "Epoch 40001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.497993\n",
      "Test Avg loss: 0.502404 \n",
      "\n",
      "Epoch 50001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.492822\n",
      "Test Avg loss: 0.506967 \n",
      "\n",
      "Epoch 60001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.488379\n",
      "Test Avg loss: 0.511469 \n",
      "\n",
      "Epoch 70001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.484555\n",
      "Test Avg loss: 0.515882 \n",
      "\n",
      "Epoch 80001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.481256\n",
      "Test Avg loss: 0.520181 \n",
      "\n",
      "Epoch 90001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.478408\n",
      "Test Avg loss: 0.524350 \n",
      "\n",
      "Epoch 100001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.475945\n",
      "Test Avg loss: 0.528376 \n",
      "\n",
      "Epoch 110001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.473812\n",
      "Test Avg loss: 0.532250 \n",
      "\n",
      "Epoch 120001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.471964\n",
      "Test Avg loss: 0.535969 \n",
      "\n",
      "Epoch 130001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.470361\n",
      "Test Avg loss: 0.539530 \n",
      "\n",
      "Epoch 140001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.468970\n",
      "Test Avg loss: 0.542930 \n",
      "\n",
      "Epoch 150001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.467762\n",
      "Test Avg loss: 0.546172 \n",
      "\n",
      "Epoch 160001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.466711\n",
      "Test Avg loss: 0.549258 \n",
      "\n",
      "Epoch 170001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.465798\n",
      "Test Avg loss: 0.552190 \n",
      "\n",
      "Epoch 180001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.465004\n",
      "Test Avg loss: 0.554973 \n",
      "\n",
      "Epoch 190001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.464313\n",
      "Test Avg loss: 0.557611 \n",
      "\n",
      "Epoch 200001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.463711\n",
      "Test Avg loss: 0.560108 \n",
      "\n",
      "Epoch 210001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.463187\n",
      "Test Avg loss: 0.562469 \n",
      "\n",
      "Epoch 220001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.462730\n",
      "Test Avg loss: 0.564701 \n",
      "\n",
      "Epoch 230001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.462332\n",
      "Test Avg loss: 0.566808 \n",
      "\n",
      "Epoch 240001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.461985\n",
      "Test Avg loss: 0.568796 \n",
      "\n",
      "Epoch 250001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.461683\n",
      "Test Avg loss: 0.570670 \n",
      "\n",
      "Epoch 260001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.461420\n",
      "Test Avg loss: 0.572436 \n",
      "\n",
      "Epoch 270001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.461190\n",
      "Test Avg loss: 0.574099 \n",
      "\n",
      "Epoch 280001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460990\n",
      "Test Avg loss: 0.575663 \n",
      "\n",
      "Epoch 290001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460815\n",
      "Test Avg loss: 0.577135 \n",
      "\n",
      "Epoch 300001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460663\n",
      "Test Avg loss: 0.578519 \n",
      "\n",
      "Epoch 310001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460530\n",
      "Test Avg loss: 0.579819 \n",
      "\n",
      "Epoch 320001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460414\n",
      "Test Avg loss: 0.581040 \n",
      "\n",
      "Epoch 330001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460313\n",
      "Test Avg loss: 0.582187 \n",
      "\n",
      "Epoch 340001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460224\n",
      "Test Avg loss: 0.583264 \n",
      "\n",
      "Epoch 350001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460147\n",
      "Test Avg loss: 0.584275 \n",
      "\n",
      "Epoch 360001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460080\n",
      "Test Avg loss: 0.585223 \n",
      "\n",
      "Epoch 370001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.460021\n",
      "Test Avg loss: 0.586112 \n",
      "\n",
      "Epoch 380001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459970\n",
      "Test Avg loss: 0.586945 \n",
      "\n",
      "Epoch 390001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459926\n",
      "Test Avg loss: 0.587727 \n",
      "\n",
      "Epoch 400001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459887\n",
      "Test Avg loss: 0.588459 \n",
      "\n",
      "Epoch 410001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459853\n",
      "Test Avg loss: 0.589145 \n",
      "\n",
      "Epoch 420001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459823\n",
      "Test Avg loss: 0.589788 \n",
      "\n",
      "Epoch 430001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459797\n",
      "Test Avg loss: 0.590391 \n",
      "\n",
      "Epoch 440001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459774\n",
      "Test Avg loss: 0.590955 \n",
      "\n",
      "Epoch 450001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459754\n",
      "Test Avg loss: 0.591483 \n",
      "\n",
      "Epoch 460001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459737\n",
      "Test Avg loss: 0.591977 \n",
      "\n",
      "Epoch 470001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459722\n",
      "Test Avg loss: 0.592440 \n",
      "\n",
      "Epoch 480001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459709\n",
      "Test Avg loss: 0.592874 \n",
      "\n",
      "Epoch 490001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459697\n",
      "Test Avg loss: 0.593279 \n",
      "\n",
      "Epoch 500001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459687\n",
      "Test Avg loss: 0.593659 \n",
      "\n",
      "Epoch 510001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459679\n",
      "Test Avg loss: 0.594014 \n",
      "\n",
      "Epoch 520001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459671\n",
      "Test Avg loss: 0.594346 \n",
      "\n",
      "Epoch 530001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459664\n",
      "Test Avg loss: 0.594657 \n",
      "\n",
      "Epoch 540001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459658\n",
      "Test Avg loss: 0.594947 \n",
      "\n",
      "Epoch 550001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459653\n",
      "Test Avg loss: 0.595219 \n",
      "\n",
      "Epoch 560001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459649\n",
      "Test Avg loss: 0.595474 \n",
      "\n",
      "Epoch 570001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459645\n",
      "Test Avg loss: 0.595712 \n",
      "\n",
      "Epoch 580001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459641\n",
      "Test Avg loss: 0.595934 \n",
      "\n",
      "Epoch 590001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459638\n",
      "Test Avg loss: 0.596142 \n",
      "\n",
      "Epoch 600001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459636\n",
      "Test Avg loss: 0.596337 \n",
      "\n",
      "Epoch 610001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459633\n",
      "Test Avg loss: 0.596519 \n",
      "\n",
      "Epoch 620001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459631\n",
      "Test Avg loss: 0.596689 \n",
      "\n",
      "Epoch 630001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459629\n",
      "Test Avg loss: 0.596848 \n",
      "\n",
      "Epoch 640001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459628\n",
      "Test Avg loss: 0.596997 \n",
      "\n",
      "Epoch 650001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459626\n",
      "Test Avg loss: 0.597136 \n",
      "\n",
      "Epoch 660001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459625\n",
      "Test Avg loss: 0.597266 \n",
      "\n",
      "Epoch 670001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459624\n",
      "Test Avg loss: 0.597388 \n",
      "\n",
      "Epoch 680001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459623\n",
      "Test Avg loss: 0.597501 \n",
      "\n",
      "Epoch 690001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459622\n",
      "Test Avg loss: 0.597608 \n",
      "\n",
      "Epoch 700001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459622\n",
      "Test Avg loss: 0.597707 \n",
      "\n",
      "Epoch 710001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459621\n",
      "Test Avg loss: 0.597800 \n",
      "\n",
      "Epoch 720001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459620\n",
      "Test Avg loss: 0.597887 \n",
      "\n",
      "Epoch 730001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459620\n",
      "Test Avg loss: 0.597968 \n",
      "\n",
      "Epoch 740001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459619\n",
      "Test Avg loss: 0.598044 \n",
      "\n",
      "Epoch 750001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459619\n",
      "Test Avg loss: 0.598115 \n",
      "\n",
      "Epoch 760001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459618\n",
      "Test Avg loss: 0.598181 \n",
      "\n",
      "Epoch 770001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459618\n",
      "Test Avg loss: 0.598243 \n",
      "\n",
      "Epoch 780001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459618\n",
      "Test Avg loss: 0.598301 \n",
      "\n",
      "Epoch 790001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459617\n",
      "Test Avg loss: 0.598355 \n",
      "\n",
      "Epoch 800001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459617\n",
      "Test Avg loss: 0.598406 \n",
      "\n",
      "Epoch 810001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459617\n",
      "Test Avg loss: 0.598453 \n",
      "\n",
      "Epoch 820001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459617\n",
      "Test Avg loss: 0.598497 \n",
      "\n",
      "Epoch 830001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598539 \n",
      "\n",
      "Epoch 840001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598577 \n",
      "\n",
      "Epoch 850001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598614 \n",
      "\n",
      "Epoch 860001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598648 \n",
      "\n",
      "Epoch 870001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598679 \n",
      "\n",
      "Epoch 880001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598709 \n",
      "\n",
      "Epoch 890001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598736 \n",
      "\n",
      "Epoch 900001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459616\n",
      "Test Avg loss: 0.598762 \n",
      "\n",
      "Epoch 910001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598786 \n",
      "\n",
      "Epoch 920001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598809 \n",
      "\n",
      "Epoch 930001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598830 \n",
      "\n",
      "Epoch 940001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598850 \n",
      "\n",
      "Epoch 950001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598868 \n",
      "\n",
      "Epoch 960001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598886 \n",
      "\n",
      "Epoch 970001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598902 \n",
      "\n",
      "Epoch 980001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598917 \n",
      "\n",
      "Epoch 990001\n",
      "-------------------------------\n",
      "Train Avg loss: 0.459615\n",
      "Test Avg loss: 0.598931 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "learning_rate = 1e-2\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "epochs = 1000000\n",
    "for t in range(epochs):\n",
    "    if t % 10000 == 0:\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c477d714-8f28-4376-98ee-1e3170c059e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2071],\n",
      "        [-0.2071],\n",
      "        [-0.2071],\n",
      "        ...,\n",
      "        [-0.2072],\n",
      "        [-0.2072],\n",
      "        [-0.2072]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "k_sample = tensor(np.linspace(0.2, 0.3, 1001)).type(torch.float)\n",
    "#k_sample = train_dataloader.dataset[:,0].reshape(-1,1)\n",
    "model_out = model.forward(k_sample.reshape(-1,1))\n",
    "print(model_out)\n",
    "\n",
    "\n",
    "\n",
    "#print(torch.sum((model_out - train_dataloader.dataset[:,1].reshape(-1,1))**2)/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83d3915f-fe3e-4811-84ba-a0f3f555456d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_val_data_i_j.X/1000, train_val_data_i_j.y,\n",
    "                c=\"#b2df8a\", marker=\".\", label=\"Training data\")\n",
    "plt.scatter(test_data_i_j.X/1000, test_data_i_j.y, c=\"#b2df8a\", marker=\"*\", label=\"Test data\")\n",
    "plt.plot(k_sample, model_out[:,0].detach().numpy(), c=\"#1f78b4\", label=\"Best solution\")\n",
    "plt.xlabel(r\"$Re$\")\n",
    "plt.ylabel(r\"$A_{ij}$\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
